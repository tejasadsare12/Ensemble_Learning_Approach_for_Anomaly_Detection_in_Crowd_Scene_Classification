{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Vertical Flip**"
      ],
      "metadata": {
        "id": "vC7NyvoyWIEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Open the input video file\n",
        "cap = cv2.VideoCapture('/content/Road_Acc2.mp4')\n",
        "\n",
        "# Define the codec and output video file parameters\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "frame_size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "out = cv2.VideoWriter('flipped_video.mp4', fourcc, fps, frame_size)\n",
        "\n",
        "# Loop through the frames of the input video\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Check if there are no more frames to read\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Flip the frame vertically\n",
        "    flipped_frame = cv2.flip(frame, 0)\n",
        "\n",
        "    # Write the flipped frame to the output video file\n",
        "    out.write(flipped_frame)\n",
        "\n",
        "    # Display the flipped frame (optional)\n",
        "    # cv2.imshow('Flipped Video', flipped_frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the input and output video files\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "# Close all windows (optional)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "xrzWvjU_q_Qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Horizontal Flip**"
      ],
      "metadata": {
        "id": "0WJLmvUHWPVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Open the input video file\n",
        "cap = cv2.VideoCapture('/content/Road_Acc2.mp4')\n",
        "\n",
        "# Define the codec and output video file parameters\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "frame_size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "out = cv2.VideoWriter('flipped_video_horizontal.mp4', fourcc, fps, frame_size)\n",
        "\n",
        "# Loop through the frames of the input video\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Check if there are no more frames to read\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Flip the frame horizontally\n",
        "    flipped_frame = cv2.flip(frame, 1)\n",
        "\n",
        "    # Write the flipped frame to the output video file\n",
        "    out.write(flipped_frame)\n",
        "\n",
        "    # Display the flipped frame (optional)\n",
        "    # cv2.imshow('Flipped Video', flipped_frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the input and output video files\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "# Close all windows (optional)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "v_GxoyoarCTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sheared Videos**"
      ],
      "metadata": {
        "id": "YSCrdy7CWPMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Open the input video file\n",
        "cap = cv2.VideoCapture('/content/Road_Acc2.mp4')\n",
        "\n",
        "# Define the codec and output video file parameters\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "frame_size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "out = cv2.VideoWriter('sheared_video.mp4', fourcc, fps, frame_size)\n",
        "\n",
        "# Define the vertical shear transformation matrix\n",
        "M = np.float32([[1, 0.5, 0],\n",
        "                [0, 1, 0], \n",
        "                [0, 0, 1]])\n",
        "\n",
        "# Loop through the frames of the input video\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Check if there are no more frames to read\n",
        "    if not ret:\n",
        "        break\n",
        "    shear_angle = 0.5\n",
        "    # Apply the vertical shear transformation to the frame\n",
        "    rows, cols, _ = frame.shape\n",
        "    M[:,3] = [shear_angle*rows, 0]\n",
        "    sheared_frame = cv2.warpAffine(frame, M, (cols, rows))\n",
        "\n",
        "    # Write the sheared frame to the output video file\n",
        "    out.write(sheared_frame)\n",
        "\n",
        "    # Display the sheared frame (optional)\n",
        "    # cv2.imshow('Sheared Video', sheared_frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the input and output video files\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "# Close all windows (optional)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "gHhIX3Fkq1VE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Increase the Brightness**"
      ],
      "metadata": {
        "id": "b8muwNvYWPDZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBFnz0fdWDg6"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "# Load the input video\n",
        "cap = cv2.VideoCapture('/content/Road_Acc2.mp4')\n",
        "\n",
        "# Get the video properties\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Create a VideoWriter object to save the output video\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('outputb.mp4', fourcc, fps, (width, height))\n",
        "\n",
        "# Loop through the frames of the video\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "        # Increase the brightness of the frame\n",
        "        brightness = 150 # Increase this value to increase brightness\n",
        "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "        h, s, v = cv2.split(hsv)\n",
        "        v = cv2.add(v, brightness)\n",
        "        v[v > 255] = 255\n",
        "        hsv = cv2.merge((h, s, v))\n",
        "        frame = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "        \n",
        "        # Write the modified frame to the output video\n",
        "        out.write(frame)\n",
        "        \n",
        "        # Display the frame (optional)\n",
        "        # cv2.imshow('frame', frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# Release the resources\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "folder_path = \"/path/to/folder\"\n",
        "\n",
        "# Use glob to get all .mp4 files in the folder\n",
        "videos = glob.glob(os.path.join(folder_path, \"*.mp4\"))\n",
        "\n",
        "# Iterate through all videos\n",
        "for video in videos:\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(video)\n",
        "\n",
        "    # Read the first frame\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Process each frame in the video\n",
        "    while ret:\n",
        "        # Apply vertical flip transformation to the frame\n",
        "        flipped_frame = cv2.flip(frame, 0)\n",
        "\n",
        "        # Use the flipped frame for machine learning\n",
        "        model.fit(flipped_frame)\n",
        "\n",
        "        # Read the next frame\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "    # Release the video file\n",
        "    cap.release()\n",
        "\n"
      ],
      "metadata": {
        "id": "Ty2ZJ6bXX2RW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "folder_path = \"/path/to/folder\"\n",
        "output_path = \"/path/to/output/folder\"\n",
        "\n",
        "# Use glob to get all .mp4 files in the folder\n",
        "videos = glob.glob(os.path.join(folder_path, \"*.mp4\"))\n",
        "\n",
        "# Iterate through all videos\n",
        "for video in videos:\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(video)\n",
        "\n",
        "    # Read the first frame\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Process each frame in the video\n",
        "    frame_count = 0\n",
        "    while ret:\n",
        "        # Apply vertical flip transformation to the frame\n",
        "        flipped_frame = cv2.flip(frame, 0)\n",
        "\n",
        "        # Use the flipped frame for machine learning\n",
        "        model.fit(flipped_frame)\n",
        "\n",
        "        # Save the flipped frame to disk\n",
        "        output_file = os.path.join(output_path, f\"frame_{frame_count:04d}.png\")\n",
        "        cv2.imwrite(output_file, flipped_frame)\n",
        "\n",
        "        # Read the next frame\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        # Increment the frame counter\n",
        "        frame_count += 1\n",
        "\n",
        "    # Release the video file\n",
        "    cap.release()\n"
      ],
      "metadata": {
        "id": "TKkFD9ReYfTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "g4dvR41wWOwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/Data/MLDLdataset/DatasetsMLDL/explosion\"\n",
        "output_path = \"/content/drive/MyDrive/Dataset/output.mp4\"\n",
        "\n",
        "# Use glob to get all .mp4 files in the folder\n",
        "videos = glob.glob(os.path.join(folder_path, \"*.mp4\"))\n",
        "\n",
        "# Define the output video codec and frame rate\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "fps = 30\n",
        "\n",
        "# Iterate through all videos\n",
        "for video in videos:\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(video)\n",
        "\n",
        "    # Get the video dimensions\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Create the output video writer\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Process each frame in the video\n",
        "    frame_count = 0\n",
        "    while True:\n",
        "        # Read a frame from the video file\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            # End of video\n",
        "            break\n",
        "\n",
        "        # Apply vertical flip transformation to the frame\n",
        "        flipped_frame = cv2.flip(frame, 0)\n",
        "\n",
        "        # Use the flipped frame for machine learning\n",
        "        # model.fit(flipped_frame)\n",
        "\n",
        "        # Write the flipped frame to the output video\n",
        "        out.write(flipped_frame)\n",
        "\n",
        "        # Increment the frame counter\n",
        "        frame_count += 1\n",
        "\n",
        "    # Release the video file and output video writer\n",
        "    cap.release()\n",
        "    out.release()\n"
      ],
      "metadata": {
        "id": "yL_K9oLdZrqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsqNYlfPZtAB",
        "outputId": "7803e15d-e39f-428c-fd17-5e265dbf14c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vertical"
      ],
      "metadata": {
        "id": "exaABzkTb5xm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/Data/MLDLdataset/DatasetsMLDL/Road_acc\"\n",
        "\n",
        "# Use glob to get all .mp4 files in the folder\n",
        "videos = glob.glob(os.path.join(folder_path, \"*.mp4\"))\n",
        "\n",
        "# Define the output video codec and frame rate\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "fps = 30\n",
        "\n",
        "# Iterate through all videos\n",
        "for video in videos:\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(video)\n",
        "\n",
        "    # Get the base filename of the input video file\n",
        "    base_filename = os.path.splitext(os.path.basename(video))[0]\n",
        "\n",
        "    # Construct the output video filename\n",
        "    output_path = os.path.join(\"/content/drive/MyDrive/Data/Augmented_Data/Road_accident\", f\"{base_filename}_outputver.mp4\")\n",
        "\n",
        "    # Get the video dimensions\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Create the output video writer\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Process each frame in the video\n",
        "    frame_count = 0\n",
        "    while True:\n",
        "        # Read a frame from the video file\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            # End of video\n",
        "            break\n",
        "\n",
        "        # Apply vertical flip transformation to the frame\n",
        "        flipped_frame = cv2.flip(frame, 0)\n",
        "\n",
        "        # Use the flipped frame for machine learning\n",
        "        # model.fit(flipped_frame)\n",
        "\n",
        "        # Write the flipped frame to the output video\n",
        "        out.write(flipped_frame)\n",
        "\n",
        "        # Increment the frame counter\n",
        "        frame_count += 1\n",
        "\n",
        "    # Release the video file and output video writer\n",
        "    cap.release()\n",
        "    out.release()\n"
      ],
      "metadata": {
        "id": "cjFhBSLvbPFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Horizontal"
      ],
      "metadata": {
        "id": "6_CjqAuAb7jN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/Data/MLDLdataset/DatasetsMLDL/Fighting\"\n",
        "\n",
        "\n",
        "# Use glob to get all .mp4 files in the folder\n",
        "videos = glob.glob(os.path.join(folder_path, \"*.mp4\"))\n",
        "\n",
        "# Define the output video codec and frame rate\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "fps = 30\n",
        "\n",
        "# Iterate through all videos\n",
        "for video in videos:\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(video)\n",
        "\n",
        "    # Get the base filename of the input video file\n",
        "    base_filename = os.path.splitext(os.path.basename(video))[0]\n",
        "\n",
        "    # Construct the output video filename\n",
        "    output_path = os.path.join(\"/content/drive/MyDrive/Data/Augmented_Data/Fighing\", f\"{base_filename}_outputhorizontal.mp4\")\n",
        "\n",
        "    # Get the video dimensions\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Create the output video writer\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Process each frame in the video\n",
        "    frame_count = 0\n",
        "    while True:\n",
        "        # Read a frame from the video file\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            # End of video\n",
        "            break\n",
        "\n",
        "        # Apply vertical flip transformation to the frame\n",
        "        flipped_frame = cv2.flip(frame, 1)\n",
        "\n",
        "        # Use the flipped frame for machine learning\n",
        "        # model.fit(flipped_frame)\n",
        "\n",
        "        # Write the flipped frame to the output video\n",
        "        out.write(flipped_frame)\n",
        "\n",
        "        # Increment the frame counter\n",
        "        frame_count += 1\n",
        "\n",
        "    # Release the video file and output video writer\n",
        "    cap.release()\n",
        "    out.release()\n"
      ],
      "metadata": {
        "id": "Q5ZX8MvAb8Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sheared"
      ],
      "metadata": {
        "id": "QzzTE7rncmO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/Data/MLDLdataset/DatasetsMLDL/Road_acc\"\n",
        "\n",
        "\n",
        "# Define the shear transformation matrix\n",
        "shear_angle = 20  # in degrees\n",
        "shear_matrix = np.array([[1, np.tan(np.deg2rad(shear_angle)), 0],\n",
        "                         [0, 1, 0]])\n",
        "\n",
        "# Use glob to get all .mp4 files in the folder\n",
        "videos = glob.glob(os.path.join(folder_path, \"*.mp4\"))\n",
        "\n",
        "# Define the output video codec and frame rate\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "fps = 30\n",
        "\n",
        "# Iterate through all videos\n",
        "for video in videos:\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(video)\n",
        "\n",
        "    # Get the base filename of the input video file\n",
        "    base_filename = os.path.splitext(os.path.basename(video))[0]\n",
        "\n",
        "    # Construct the output video filename\n",
        "    output_path = os.path.join(\"/content/drive/MyDrive/Data/Augmented_Data/Road_accident\", f\"{base_filename}_outputsheared.mp4\")\n",
        "\n",
        "    # Get the video dimensions\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Create the output video writer\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Process each frame in the video\n",
        "    frame_count = 0\n",
        "    while True:\n",
        "        # Read a frame from the video file\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            # End of video\n",
        "            break\n",
        "\n",
        "        # Apply the shear transformation to the frame\n",
        "        sheared_frame = cv2.warpAffine(frame, shear_matrix, (width, height))\n",
        "\n",
        "        # Use the sheared frame for machine learning\n",
        "        # model.fit(sheared_frame)\n",
        "\n",
        "        # Write the sheared frame to the output video\n",
        "        out.write(sheared_frame)\n",
        "\n",
        "        # Increment the frame counter\n",
        "        frame_count += 1\n",
        "\n",
        "    # Release the video file and output video writer\n",
        "    cap.release()\n",
        "    out.release()\n"
      ],
      "metadata": {
        "id": "-gJNlxeyb_oW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/Data/MLDLdataset/DatasetsMLDL/Road_acc\"\n",
        "\n",
        "output_path = \"/content/drive/MyDrive/Data/Augmented_Data/Road_accident\"\n",
        "\n",
        "# Define the brightness adjustment factor\n",
        "brightness_factor = 130  # adjust brightness by adding this value to the pixel intensities\n",
        "\n",
        "# Use glob to get all .mp4 files in the folder\n",
        "videos = glob.glob(os.path.join(folder_path, \"*.mp4\"))\n",
        "\n",
        "# Iterate through all videos\n",
        "for video in videos:\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(video)\n",
        "\n",
        "    # Read the video dimensions\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Define the output video codec and frame rate\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Define the output video writer\n",
        "    base_filename = os.path.splitext(os.path.basename(video))[0]\n",
        "    output_file = os.path.join(output_path, f\"{base_filename}_output.mp4\")\n",
        "    out = cv2.VideoWriter(output_file, fourcc, fps, (width, height))\n",
        "\n",
        "    # Process each frame in the video\n",
        "    frame_count = 0\n",
        "    while True:\n",
        "        # Read a frame from the video file\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            # End of video\n",
        "            break\n",
        "\n",
        "        # Adjust the brightness of the frame\n",
        "        brightness_adjusted_frame = cv2.add(frame, brightness_factor)\n",
        "\n",
        "        # Use the brightness-adjusted frame for machine learning\n",
        "        # model.fit(brightness_adjusted_frame)\n",
        "\n",
        "        # Write the brightness-adjusted frame to the output video\n",
        "        out.write(brightness_adjusted_frame)\n",
        "\n",
        "        # Increment the frame counter\n",
        "        frame_count += 1\n",
        "\n",
        "    # Release the video file and output video writer\n",
        "    cap.release()\n",
        "    out.release()\n"
      ],
      "metadata": {
        "id": "1b6Y435fdFLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pytube import YouTube\n",
        "\n",
        "# Define the YouTube link and output directory\n",
        "youtube_link = \"https://www.youtube.com/watch?v=N2Pvr22gTo4\"\n",
        "output_dir = \"/content\"\n",
        "\n",
        "# Create a YouTube object for the given link\n",
        "yt = YouTube(youtube_link)\n",
        "\n",
        "# Get the highest quality MP4 stream\n",
        "mp4_stream = yt.streams.filter(file_extension=\"mp4\", adaptive=True).order_by(\"resolution\").desc().first()\n",
        "\n",
        "# Download the MP4 file\n",
        "mp4_stream.download(output_dir)\n",
        "\n",
        "# Rename the downloaded file to a more descriptive name\n",
        "output_file = os.path.join(output_dir, f\"{yt.title}.mp4\")\n",
        "os.rename(mp4_stream.default_filename, output_file)\n"
      ],
      "metadata": {
        "id": "StAkqfwgkJ_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtcVCuy5kP-2",
        "outputId": "8a94bcf4-9954-4dbd-8841-aff285e48e2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-12.1.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-12.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/Data/Road_acc.zip\" -d \"/content/drive/MyDrive/Data/Augmented_Data/Road_acc\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F80XiBR-kSkZ",
        "outputId": "e9c899cc-914b-4d43-8c1c-b87577b0ffe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Data/Road_acc.zip\n",
            "  inflating: /content/drive/MyDrive/Data/Augmented_Data/Road_acc/Road_acc/Road_Acc1.mp4  \n",
            "  inflating: /content/drive/MyDrive/Data/Augmented_Data/Road_acc/Road_acc/Road_Acc10.mp4  \n",
            "  inflating: /content/drive/MyDrive/Data/Augmented_Data/Road_acc/Road_acc/Road_Acc11.mp4  \n",
            "  inflating: /content/drive/MyDrive/Data/Augmented_Data/Road_acc/Road_acc/Road_Acc12.mp4  \n",
            "  inflating: /content/drive/MyDrive/Data/Augmented_Data/Road_acc/Road_acc/Road_Acc13.mp4  \n",
            "  inflating: /content/drive/MyDrive/Data/Augmented_Data/Road_acc/Road_acc/Road_Acc14.mp4  \n",
            "  inflating: /content/drive/MyDrive/Data/Augmented_Data/Road_acc/Road_acc/Road_Acc15.mp4  \n",
            "  inflating: /content/drive/MyDrive/Data/Augmented_Data/Road_acc/Road_acc/Road_Acc16.mp4  \n",
            "  inflating: /content/drive/MyDrive/Data/Augmented_Data/Road_acc/Road_acc/Road_Acc17.mp4  \n",
            "  inflating: /content/drive/MyDrive/Data/Augmented_Data/Road_acc/Road_acc/Road_Acc18.mp4  \n",
            "  inflating: /content/drive/MyDrive/Data/Augmented_Data/Road_acc/Road_acc/Road_Acc19.mp4  \n",
            "  inflating: /content/drive/MyDrive/Data/Augmented_Data/Road_acc/Road_acc/Road_Acc2.mp4  \n",
            "  inflating: /content/drive/MyDrive/Data/Augmented_Data/Road_acc/Road_acc/Road_Acc20.mp4  \n",
            "  inflating: /content/drive/MyDrive/Data/Augmented_Data/Road_acc/Road_acc/Road_Acc3.mp4  \n",
            "  inflating: /content/drive/MyDrive/Data/Augmented_Data/Road_acc/Road_acc/Road_Acc4.mp4  \n",
            "  inflating: /content/drive/MyDrive/Data/Augmented_Data/Road_acc/Road_acc/Road_Acc5.mp4  \n",
            "  inflating: /content/drive/MyDrive/Data/Augmented_Data/Road_acc/Road_acc/Road_Acc6.mp4  \n",
            "  inflating: /content/drive/MyDrive/Data/Augmented_Data/Road_acc/Road_acc/Road_Acc7.mp4  \n",
            "  inflating: /content/drive/MyDrive/Data/Augmented_Data/Road_acc/Road_acc/Road_Acc8.mp4  \n",
            "  inflating: /content/drive/MyDrive/Data/Augmented_Data/Road_acc/Road_acc/Road_Acc9.mp4  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "parent_folder_path = \"/content/drive/MyDrive/Data/Augmented_Data\"\n",
        "\n",
        "folders = [\"Normal\", \"Road_accident\", \"explosion\", \"Fighting\"]\n",
        "\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(parent_folder_path, folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        num_files = len(os.listdir(folder_path))\n",
        "        print(f\"{folder} contains {num_files} files.\")\n",
        "    else:\n",
        "        print(f\"{folder} is not a directory.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATIvqnNGrlyo",
        "outputId": "9db38250-57d8-46ea-caac-fd10e2c7cdf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal contains 92 files.\n",
            "Road_accident contains 100 files.\n",
            "explosion contains 90 files.\n",
            "Fighting contains 100 files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/Data/Augmented_Data/Fighting\"\n",
        "\n",
        "files = os.listdir(folder_path)\n",
        "random_files = random.sample(files, k=50)\n",
        "\n",
        "for file in random_files:\n",
        "    file_path = os.path.join(folder_path, file)\n",
        "    if os.path.isfile(file_path):\n",
        "        os.remove(file_path)\n",
        "        print(f\"{file} has been deleted.\")\n",
        "    else:\n",
        "        print(f\"{file} is not a file.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDZcap54t-6k",
        "outputId": "594549f1-6a02-40aa-9ab1-9f1eacc4c3b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "V_845_outputhorizontal.mp4 has been deleted.\n",
            "V_928_outputhorizontal.mp4 has been deleted.\n",
            "V_12.mp4 has been deleted.\n",
            "V_64.mp4 has been deleted.\n",
            "V_30.mp4 has been deleted.\n",
            "V_20_outputhorizontal.mp4 has been deleted.\n",
            "V_957_outputhorizontal.mp4 has been deleted.\n",
            "V_861_outputhorizontal.mp4 has been deleted.\n",
            "V_72.mp4 has been deleted.\n",
            "V_34.mp4 has been deleted.\n",
            "V_16_outputhorizontal.mp4 has been deleted.\n",
            "V_68.mp4 has been deleted.\n",
            "V_78.mp4 has been deleted.\n",
            "V_884_outputhorizontal.mp4 has been deleted.\n",
            "V_850_outputhorizontal.mp4 has been deleted.\n",
            "V_70.mp4 has been deleted.\n",
            "V_67.mp4 has been deleted.\n",
            "V_77.mp4 has been deleted.\n",
            "V_861.mp4 has been deleted.\n",
            "V_23.mp4 has been deleted.\n",
            "V_35.mp4 has been deleted.\n",
            "V_883_outputhorizontal.mp4 has been deleted.\n",
            "V_961.mp4 has been deleted.\n",
            "V_634.mp4 has been deleted.\n",
            "V_736.mp4 has been deleted.\n",
            "V_18.mp4 has been deleted.\n",
            "V_944_outputhorizontal.mp4 has been deleted.\n",
            "V_63.mp4 has been deleted.\n",
            "V_632.mp4 has been deleted.\n",
            "V_32.mp4 has been deleted.\n",
            "V_22_outputhorizontal.mp4 has been deleted.\n",
            "V_80.mp4 has been deleted.\n",
            "V_928.mp4 has been deleted.\n",
            "V_925.mp4 has been deleted.\n",
            "V_856_outputhorizontal.mp4 has been deleted.\n",
            "V_51_outputhorizontal.mp4 has been deleted.\n",
            "V_650.mp4 has been deleted.\n",
            "V_948.mp4 has been deleted.\n",
            "V_43.mp4 has been deleted.\n",
            "V_988_outputhorizontal.mp4 has been deleted.\n",
            "V_38.mp4 has been deleted.\n",
            "V_41.mp4 has been deleted.\n",
            "V_737.mp4 has been deleted.\n",
            "V_38_outputhorizontal.mp4 has been deleted.\n",
            "V_901.mp4 has been deleted.\n",
            "V_52.mp4 has been deleted.\n",
            "V_29.mp4 has been deleted.\n",
            "V_19_outputhorizontal.mp4 has been deleted.\n",
            "V_634_outputhorizontal.mp4 has been deleted.\n",
            "V_74.mp4 has been deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FlhFJsvmu75C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}